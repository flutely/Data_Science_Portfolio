[
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects Overview",
    "section": "",
    "text": "Description: Pick a dataset and explore it to discover insights and answer questions.\n\n\n\nDescription: Find an interesting data source, collect the data, and prepare it for analysis.\n\n\n\nDescription: A comprehensive project that shows off my data science skills.",
    "crumbs": [
      "Projects Overview"
    ]
  },
  {
    "objectID": "projects/index.html#all-projects",
    "href": "projects/index.html#all-projects",
    "title": "Projects Overview",
    "section": "",
    "text": "Description: Pick a dataset and explore it to discover insights and answer questions.\n\n\n\nDescription: Find an interesting data source, collect the data, and prepare it for analysis.\n\n\n\nDescription: A comprehensive project that shows off my data science skills.",
    "crumbs": [
      "Projects Overview"
    ]
  },
  {
    "objectID": "projects/eda.html",
    "href": "projects/eda.html",
    "title": "EDA Project",
    "section": "",
    "text": "This is coming down the pipeline. Check again later.",
    "crumbs": [
      "EDA Project"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Welcome to my data science portfolio! This site shows my journey learning data science and analytics. Here you’ll find projects that demonstrate what I’ve learned and discovered.\n\n\nThis portfolio shows my work learning data science. Each project includes:\n\nMy code with documentation\nVisualizations I created\nWhat I learned and discovered\n\nI built this site using Quarto and host it on GitHub Pages.\n\n\n\n\nProgramming: Python, Pandas for data analysis\nVisualization: Creating charts with Matplotlib and Seaborn\nData Collection: Getting data from files, websites, and APIs\nAnalysis: Finding patterns and answering questions with data\n\n\n\n\n\n\n\nLearn how I explore datasets to find interesting patterns and answer questions.\n\n\n\nSee how I gather data from different sources and prepare it for analysis.\n\n\n\nSee how I tackle a data science project beginning to end.\n\n\n\nThanks for visiting! Feel free to explore my projects and see what I’m learning."
  },
  {
    "objectID": "index.html#about-this-portfolio",
    "href": "index.html#about-this-portfolio",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "This portfolio shows my work learning data science. Each project includes:\n\nMy code with documentation\nVisualizations I created\nWhat I learned and discovered\n\nI built this site using Quarto and host it on GitHub Pages."
  },
  {
    "objectID": "index.html#skills-im-learning",
    "href": "index.html#skills-im-learning",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Programming: Python, Pandas for data analysis\nVisualization: Creating charts with Matplotlib and Seaborn\nData Collection: Getting data from files, websites, and APIs\nAnalysis: Finding patterns and answering questions with data"
  },
  {
    "objectID": "index.html#my-projects",
    "href": "index.html#my-projects",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Learn how I explore datasets to find interesting patterns and answer questions.\n\n\n\nSee how I gather data from different sources and prepare it for analysis.\n\n\n\nSee how I tackle a data science project beginning to end.\n\n\n\nThanks for visiting! Feel free to explore my projects and see what I’m learning."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "",
    "section": "Education",
    "text": "Education\n\nBrigham Young University\n\nApplied Statistics and Analytics | Expected Graduation: April 2027\n\nDean’s list (top 95% of students) since 2023\nRelevant Courses: Statistical Modeling 1 & 2, Probability and Inference 1 & 2, Calculus of Several Variables, Linear Algebra, Intro to Computer Science"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "",
    "section": "Experience",
    "text": "Experience\n\nStudent Business Analyst\n\nBrigham Young University | December 2025 - Present\n\nWrote queries to safely transport sensitive information related to Enrollment and Financial Aid\nDesigned multiple Tableau dashboards created from custom SQL scripts for clarity and usability\nMaintained data security, privacy, & upheld FERPA laws for more than 500,000 distinct people\n\n\n\n\nData Analyst Intern\n\nChristopherson Business Travel | June 2025 - September 2025\n\nWorked with large datasets (1-10M+ rows) related to call centers, client information, etc.\nCreated profitability model to determine performance based employee compensation\nAdjusted for GDP changes and COVID-19 travel shock in historic data\nRegularly presented data insights and statistical findings & communicated possible roadblocks\n\n\n\n\nMath Instructional Design Assistant\n\nBrigham Young University | January 2023 - November 2025\n\nDesigned 7 High School Math courses serving 60,000+ students in 153 countries\nTrained and mentored 3-5 student employees in web design and learning objective alignment\nUsed task management tools to coordinate tasks and deadlines (Microsoft Teams, Teamwork)\nFocused on accessibility, clarity, and student-centered design in an online format\n\n\n\n\nFull-Time Missionary\n\nThe Church of Jesus Christ of Latter-day Saints | May 2023 - November 2024\n\nVolunteer service in Uruguay"
  },
  {
    "objectID": "about.html#skills",
    "href": "about.html#skills",
    "title": "",
    "section": "Skills",
    "text": "Skills\n\nTechnical Tools:\n\nPython\nR\nSQL\nTableau\nExcel\n\n\n\nStatistical Methods:\n\nRegression\nInference\nModeling\nData Visualization\n\n\n\nSoft Skills:\n\nCritical Thinking & Problem Solving\nCollaboration & Communication\nOrganization & Dependability"
  },
  {
    "objectID": "about.html#get-to-know-me",
    "href": "about.html#get-to-know-me",
    "title": "",
    "section": "Get to Know Me",
    "text": "Get to Know Me\n\nHobbies\n\nPiano, Flute, Singing & Guitar\nRunning & Hiking\nBoard Games\n\n\n\nFun facts\n\nMy favorite color is green\n\n\n\n\nHeadshot of Me"
  },
  {
    "objectID": "cross_validation.html",
    "href": "cross_validation.html",
    "title": "Cross Validation",
    "section": "",
    "text": "Have you ever wondered how well your statistical model is doing to model the data? One way to show model accuracy is using a method called cross validation."
  },
  {
    "objectID": "cross_validation.html#overview",
    "href": "cross_validation.html#overview",
    "title": "Cross Validation",
    "section": "Overview",
    "text": "Overview\nThis page will cover the folowing: - What is Cross Validation? - \\(k\\)-fold Cross Validation - Coding Cross Validation in Python - Tradeoff between Bias and Variance\nWe’ll use Adult Income data as an example."
  },
  {
    "objectID": "cross_validation.html#what-is-cross-validation",
    "href": "cross_validation.html#what-is-cross-validation",
    "title": "Cross Validation",
    "section": "What is Cross Validation?",
    "text": "What is Cross Validation?\nCross-validation is the process of splitting a dataset into two pieces and using one to fit a model, and the other piece to check the fit."
  },
  {
    "objectID": "cross_validation.html#k-fold-cross-validation",
    "href": "cross_validation.html#k-fold-cross-validation",
    "title": "Cross Validation",
    "section": "\\(k\\)-fold Cross Validation",
    "text": "\\(k\\)-fold Cross Validation\nThere are a few steps to cross-validation\n\nSplit the data into \\(k\\) folds\n\nIn this step we divide the data into \\(k\\) sections. We will use different combinations of these sections to train our model and validate it.\n\nTrain on \\(k-1\\) folds\n\nWe will use all but one of our sections to train the data. We will create a model using it.\n\nValidate on remaining fold\n\nNext, we take the model created in the previous step and make predictions based on the last section (the one we didn’t include to train the model) and then compare the values.\n\nRepeat \\(k\\) times\n\nWe repeat this process \\(k\\) times to get all possible combinations of the sections for training and validating.\n\nAverage performance\n\nHere we take measures of performance from each of the repetitions and aggregate them to evaluate overall how well our model performed."
  },
  {
    "objectID": "cross_validation.html#coding-cross-validaion-in-python",
    "href": "cross_validation.html#coding-cross-validaion-in-python",
    "title": "Cross Validation",
    "section": "Coding Cross Validaion in Python",
    "text": "Coding Cross Validaion in Python\nWe’ll start by loading the necessary libraries and the data.\n\n\nCode\nimport numpy as np\nimport pandas as pd\n\nadult_income = pd.read_csv(\"adult.csv\")[['age', 'hours-per-week', 'class']]\n\n\nWe want to predict whether the income is greater than 50k for a given adult.\n\n\nCode\nadult_income['income'] = (adult_income['class'] == '&gt;50k').astype(int)\n\nx = adult_income[['age', 'hours-per-week']].values # Independent Variables\ny = adult_income[['income]].values # Dependent Variables\n\n\nThe following is a function to run the cross-validation process and return the results.\n\n\nCode\ndef k_fold_cv(x, y, k):\n    n = len(x) \n    indices = np.random.permutation(n) # Reorganize the data randomly to ensure randomization in our splits\n    folds = np.array_split(indices, k) # Create the folds\n    errors = []\n    for i in range(k): # Repeat the process k times\n        test_idx = folds[i]\n        train_idx = np.concatenate([folds[j] for j in range(k) if j != i]) # Combine training folds into one group\n        x_train, y_train = x[train_idx], y[train_idx]\n        x_test, y_test = x[test_idx], y[test_idx]\n        model = LinearRegression() # We use a linear regression in this example\n        model.fit(x_train, y_train) # Fit the model using training data\n        preds = model.predict(x_test) # Predict values for the test data using the model\n        mse = mean_squared_error(y_test, preds) # Use mse to evaluate the difference in predictions and acutal results\n        errors.append(mse)\n    return np.mean(errors), np.std(errors) # return information about the errors\n\n\nFor this dataset we’ll use \\(k=5\\) folds.\n\n\nCode\nmean_mse, std_mse = k_fold_cv(x, y, k = 5)\n\nprint('Mean MSE:', mean_mse)\nprint('Std Dev:', std_mse)"
  },
  {
    "objectID": "cross_validation.html#tradeoff-between-bias-and-variance",
    "href": "cross_validation.html#tradeoff-between-bias-and-variance",
    "title": "Cross Validation",
    "section": "Tradeoff Between Bias and Variance",
    "text": "Tradeoff Between Bias and Variance"
  },
  {
    "objectID": "projects/data-acquisition.html",
    "href": "projects/data-acquisition.html",
    "title": "Data Acquisition Project",
    "section": "",
    "text": "This is coming down the pipeline. Check again later.",
    "crumbs": [
      "Data Acquisition Project"
    ]
  },
  {
    "objectID": "projects/final-project.html",
    "href": "projects/final-project.html",
    "title": "Final Project",
    "section": "",
    "text": "This is coming down the pipeline. Check again later.",
    "crumbs": [
      "Final Project"
    ]
  }
]